{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMPzzqujO03GCCFEPHzCQPh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tlsgptj/2024-Samsung-AI-Challenge-Black-box-Optimization/blob/main/2024_Samsung_AI_Challenge_Black_box_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#사용가능한 알고리즘\n",
        "# 1. Xgboost\n",
        "# 2. 랜덤 포레스트 회귀 (Random Forest Regressor)\n",
        "# 3. 라이트GBM (LightGBM)"
      ],
      "metadata": {
        "id": "NFyTxtOvFHff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "HOOrI6zln2G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.drop(columns=['ID', 'y'])  # 'ID'와 'y'를 제외한 특징 사용\n",
        "y_train = train_df['y']"
      ],
      "metadata": {
        "id": "NeDNgpTyn53j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_df.drop(columns=['ID'])  # 'ID'를 제외한 특징 사용\n",
        "test_ids = test_df['ID']  # 제출을 위한 ID"
      ],
      "metadata": {
        "id": "dZGqczX7n9nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "AP8N6h-FHbWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from skopt import BayesSearchCV"
      ],
      "metadata": {
        "id": "8VvTl_UkoFEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(random_state=42)"
      ],
      "metadata": {
        "id": "K2_zFY37oAMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_space = {\n",
        "    'n_estimators': (10, 100),\n",
        "    'max_depth': (1, 20),\n",
        "    'min_samples_split': (2, 10),\n",
        "    'min_samples_leaf': (1, 10)\n",
        "}"
      ],
      "metadata": {
        "id": "CoHQAhE9ohGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = BayesSearchCV(estimator=rf, search_spaces=param_space, n_iter=32, cv=3, n_jobs=-1, random_state=42)\n",
        "opt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "pBrg8PGVoluD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best hyperparameters:\", opt.best_params_)\n",
        "\n",
        "# 최적 모델로 테스트 데이터 예측\n",
        "y_test_pred = opt.predict(X_test)"
      ],
      "metadata": {
        "id": "59VS70Usque5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best hyperparameters: OrderedDict([('max_depth', 7), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 100)])"
      ],
      "metadata": {
        "id": "j3VKjwqGxP_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 평가 (학습 데이터에서 성능 검증)\n",
        "# 여기서는 train 데이터의 20%를 검증용으로 다시 나누어 성능 평가\n",
        "X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "opt.fit(X_train_part, y_train_part)\n",
        "y_valid_pred = opt.predict(X_valid)"
      ],
      "metadata": {
        "id": "T6arQgEqq0B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_valid, y_valid_pred)\n",
        "r2 = r2_score(y_valid, y_valid_pred)"
      ],
      "metadata": {
        "id": "0Qbo1Pg1q4GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"Validation R-squared: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "LPktbWc2q6Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = np.percentile(y_test_pred, 67)\n",
        "top_33_percent_mask = y_test_pred >= threshold"
      ],
      "metadata": {
        "id": "PbmhulzRyWvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 제출 파일 생성\n",
        "submission_df = pd.read_csv('sample_submission.csv')\n",
        "submission_df['y'] = y_test_pred\n",
        "submission_df.to_csv('updated_submission.csv', index=False)\n",
        "\n",
        "print(f\"Top 33% threshold: {threshold:.4f}\")\n",
        "print(f\"Number of samples in top 33%: {sum(top_33_percent_mask)}\")\n",
        "print(\"Submission file 'updated_submission.csv' created successfully.\")"
      ],
      "metadata": {
        "id": "T9kWzvwdq8b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 33% threshold: 84.5243\n",
        "Number of samples in top 33%: 1646\n",
        "Submission file 'submission.csv' created successfully."
      ],
      "metadata": {
        "id": "bTHBH-4A1Oqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "Ac0pmUDVIlfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XgBoost\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from skopt import BayesSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bAtzhcUbHIqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "X_train = train_df.drop(columns=['ID', 'y'])  # 'ID'와 'y'를 제외한 특징 사용\n",
        "y_train = train_df['y']\n",
        "X_test = test_df.drop(columns=['ID'])  # 'ID'를 제외한 특징 사용\n",
        "test_ids = test_df['ID']  # 제출을 위한 ID"
      ],
      "metadata": {
        "id": "vfNxfCYiI6lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBRegressor(random_state=42, objective='reg:squarederror')"
      ],
      "metadata": {
        "id": "vZKMpQvAI_37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_space_xgb = {\n",
        "    'n_estimators': (10, 100),\n",
        "    'max_depth': (1, 20),\n",
        "    'learning_rate': (0.01, 0.3, 'log-uniform'),\n",
        "    'subsample': (0.5, 1.0),\n",
        "    'colsample_bytree': (0.5, 1.0),\n",
        "    'min_child_weight': (1, 10)\n",
        "}"
      ],
      "metadata": {
        "id": "NsPxcaUCJCY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_xgb = BayesSearchCV(estimator=xgb_model, search_spaces=param_space_xgb, n_iter=32, cv=3, n_jobs=-1, random_state=42)"
      ],
      "metadata": {
        "id": "oHJJSg2CJEp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_xgb.fit(X_train, y_train)\n",
        "print(\"Best hyperparameters for XGBoost:\", opt_xgb.best_params_)"
      ],
      "metadata": {
        "id": "sAhxwIgwJHdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best hyperparameters for XGBoost: OrderedDict([('colsample_bytree', 0.7224162561505759), ('learning_rate', 0.22754356809600707), ('max_depth', 3), ('min_child_weight', 5), ('n_estimators', 27), ('subsample', 0.7268326719031495)])"
      ],
      "metadata": {
        "id": "kqZadJwtKG3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_xgb = opt_xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "z8DoZykLH-BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "opt_xgb.fit(X_train_part, y_train_part)\n",
        "y_valid_pred_xgb = opt_xgb.predict(X_valid)\n",
        "mse_xgb = mean_squared_error(y_valid, y_valid_pred_xgb)\n",
        "r2_xgb = r2_score(y_valid, y_valid_pred_xgb)\n",
        "print(f\"Validation Mean Squared Error (XGBoost): {mse_xgb:.4f}\")\n",
        "print(f\"Validation R-squared (XGBoost): {r2_xgb:.4f}\")"
      ],
      "metadata": {
        "id": "5-B0MOd3KFsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation Mean Squared Error (XGBoost): 2.5717\n",
        "Validation R-squared (XGBoost): 0.6407"
      ],
      "metadata": {
        "id": "QNk4Ea2ALKGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_xgb = np.percentile(y_test_pred_xgb, 67)\n",
        "top_33_percent_mask_xgb = y_test_pred_xgb >= threshold_xgb"
      ],
      "metadata": {
        "id": "MoOqNWsXKNH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df_xgb = pd.read_csv('sample_submission.csv')\n",
        "submission_df_xgb['y'] = y_test_pred_xgb\n",
        "submission_df_xgb.to_csv('xgb_updated_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "P2Ml4Do0LNSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Top 33% threshold (XGBoost): {threshold_xgb:.4f}\")\n",
        "print(f\"Number of samples in top 33% (XGBoost): {sum(top_33_percent_mask_xgb)}\")\n",
        "print(\"Submission file 'xgb_updated_submission.csv' created successfully.\")"
      ],
      "metadata": {
        "id": "upl560puLPMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 33% threshold (XGBoost): 84.5228\n",
        "Number of samples in top 33% (XGBoost): 1646\n",
        "Submission file 'xgb_updated_submission.csv' created successfully."
      ],
      "metadata": {
        "id": "pXrCscowLWAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install CatBoost"
      ],
      "metadata": {
        "id": "CcGxs725L06B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cat Boost\n",
        "from catboost import CatBoostRegressor"
      ],
      "metadata": {
        "id": "uiYv8DXhLQ7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = CatBoostRegressor(random_state=42, verbose=0)"
      ],
      "metadata": {
        "id": "Qtv7stMFLzS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 검색 공간 정의\n",
        "param_space_cat = {\n",
        "    'iterations': (100, 1000),\n",
        "    'depth': (3, 12),\n",
        "    'learning_rate': (0.01, 0.3, 'log-uniform'),\n",
        "    'l2_leaf_reg': (1, 10),\n",
        "    'bagging_temperature': (0, 1.0),\n",
        "}"
      ],
      "metadata": {
        "id": "UA2U5KZXMBZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_cat = BayesSearchCV(estimator=cat_model, search_spaces=param_space_cat, n_iter=50, cv=3, n_jobs=-1, random_state=42)"
      ],
      "metadata": {
        "id": "XLKSlgqsMDCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_cat.fit(X_train, y_train)\n",
        "print(\"Best hyperparameters for CatBoost:\", opt_cat.best_params_)"
      ],
      "metadata": {
        "id": "yYZGwi0pMFnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best hyperparameters for CatBoost: OrderedDict([('bagging_temperature', 0.9213569982250611), ('depth', 12), ('iterations', 594), ('l2_leaf_reg', 9), ('learning_rate', 0.01800427693994094)])"
      ],
      "metadata": {
        "id": "9w4TQKoTYsIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_cat = opt_cat.predict(X_test)"
      ],
      "metadata": {
        "id": "aN7KTaNjMHQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "opt_cat.fit(X_train_part, y_train_part)\n",
        "y_valid_pred_cat = opt_cat.predict(X_valid)\n",
        "mse_cat = mean_squared_error(y_valid, y_valid_pred_cat)\n",
        "r2_cat = r2_score(y_valid, y_valid_pred_cat)\n",
        "print(f\"Validation Mean Squared Error (CatBoost): {mse_cat:.4f}\")\n",
        "print(f\"Validation R-squared (CatBoost): {r2_cat:.4f}\")"
      ],
      "metadata": {
        "id": "BEXjicmfYXAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_cat = np.percentile(y_test_pred_cat, 67)\n",
        "top_33_percent_mask_cat = y_test_pred_cat >= threshold_cat"
      ],
      "metadata": {
        "id": "fkwJ8OoRYdPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df_cat = pd.read_csv('sample_submission.csv')\n",
        "submission_df_cat['y'] = y_test_pred_cat\n",
        "submission_df_cat.to_csv('cat_updated_submission.csv', index=False)\n",
        "\n",
        "print(f\"Top 33% threshold (CatBoost): {threshold_cat:.4f}\")\n",
        "print(f\"Number of samples in top 33% (CatBoost): {sum(top_33_percent_mask_cat)}\")\n",
        "print(\"Submission file 'cat_updated_submission.csv' created successfully.\")"
      ],
      "metadata": {
        "id": "m3zPWUVjYfTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LightGBM 모델\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from lightgbm import LGBMRegressor\n",
        "from skopt import BayesSearchCV"
      ],
      "metadata": {
        "id": "5AuJPbLGYidK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "X_train = train_df.drop(columns=['ID', 'y'])  # 'ID'와 'y'를 제외한 특징 사용\n",
        "y_train = train_df['y']\n",
        "X_test = test_df.drop(columns=['ID'])  # 'ID'를 제외한 특징 사용\n",
        "test_ids = test_df['ID']  # 제출을 위한 ID"
      ],
      "metadata": {
        "id": "hUARGNMebtch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_model = LGBMRegressor(random_state=42)"
      ],
      "metadata": {
        "id": "kRaANWbwbvki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_space_lgbm = {\n",
        "    'n_estimators': (100, 1000),\n",
        "    'max_depth': (3, 15),\n",
        "    'learning_rate': (0.01, 0.3, 'log-uniform'),\n",
        "    'num_leaves': (20, 50),\n",
        "    'min_child_samples': (5, 30),\n",
        "    'subsample': (0.5, 1.0),\n",
        "    'colsample_bytree': (0.5, 1.0)\n",
        "}"
      ],
      "metadata": {
        "id": "FPENuQ7SbxeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_lgbm = BayesSearchCV(estimator=lgbm_model, search_spaces=param_space_lgbm, n_iter=50, cv=3, n_jobs=-1, random_state=42)"
      ],
      "metadata": {
        "id": "H33L9oIDbzSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_lgbm.fit(X_train, y_train)\n",
        "print(\"Best hyperparameters for LightGBM:\", opt_lgbm.best_params_)"
      ],
      "metadata": {
        "id": "irMK3wBTb1kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_lgbm = opt_lgbm.predict(X_test)"
      ],
      "metadata": {
        "id": "5M_f45NWb3n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "opt_lgbm.fit(X_train_part, y_train_part)\n",
        "y_valid_pred_lgbm = opt_lgbm.predict(X_valid)\n",
        "mse_lgbm = mean_squared_error(y_valid, y_valid_pred_lgbm)\n",
        "r2_lgbm = r2_score(y_valid, y_valid_pred_lgbm)\n",
        "print(f\"Validation Mean Squared Error (LightGBM): {mse_lgbm:.4f}\")\n",
        "print(f\"Validation R-squared (LightGBM): {r2_lgbm:.4f}\")"
      ],
      "metadata": {
        "id": "F67ppMG0b5dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_lgbm = np.percentile(y_test_pred_lgbm, 67)\n",
        "top_33_percent_mask_lgbm = y_test_pred_lgbm >= threshold_lgbm"
      ],
      "metadata": {
        "id": "vOpw0JBnb7aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df_lgbm = pd.read_csv('sample_submission.csv')\n",
        "submission_df_lgbm['y'] = y_test_pred_lgbm\n",
        "submission_df_lgbm.to_csv('lgbm_updated_submission.csv', index=False)\n",
        "\n",
        "print(f\"Top 33% threshold (LightGBM): {threshold_lgbm:.4f}\")\n",
        "print(f\"Number of samples in top 33% (LightGBM): {sum(top_33_percent_mask_lgbm)}\")\n",
        "print(\"Submission file 'lgbm_updated_submission.csv' created successfully.\")"
      ],
      "metadata": {
        "id": "FIT38LFAb9Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "2DIMjQTLf70i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature engneering\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "FN_z_I8rb_N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "C6NE0WozcQAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())"
      ],
      "metadata": {
        "id": "cEBxu6HQc5x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns in train_df:\", train_df.columns)"
      ],
      "metadata": {
        "id": "EtwZhjDPjxSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수치형과 범주형 특성 선택\n",
        "numerical_features = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# 'ID'와 'y'는 제거\n",
        "numerical_features = [col for col in numerical_features if col not in ['ID', 'y']]\n",
        "categorical_features = [col for col in categorical_features if col != 'ID']\n",
        "\n",
        "print(\"Numerical features:\", numerical_features)\n",
        "print(\"Categorical features:\", categorical_features)\n",
        "\n",
        "# 결측값 대체 전략 설정\n",
        "numerical_transformer = SimpleImputer(strategy='mean')\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])"
      ],
      "metadata": {
        "id": "kwRPVhMFc7Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬럼 변환기를 통해 수치형과 범주형에 다른 전처리 적용\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'  # 나머지 컬럼은 그대로 유지\n",
        ")"
      ],
      "metadata": {
        "id": "P38DQdapc9h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 전처리 및 모델을 포함하는 파이프라인 구성\n",
        "model = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('scaler', StandardScaler()),  # 스케일링 추가\n",
        "    ('model', model)\n",
        "])"
      ],
      "metadata": {
        "id": "HShba7qBkxzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 검색 공간 정의\n",
        "param_space_xgb = {\n",
        "    'model__n_estimators': (100, 1000),\n",
        "    'model__max_depth': (3, 15),\n",
        "    'model__learning_rate': (0.01, 0.3, 'log-uniform'),\n",
        "    'model__subsample': (0.5, 1.0),\n",
        "    'model__colsample_bytree': (0.5, 1.0),\n",
        "    'model__min_child_weight': (1, 10)\n",
        "}"
      ],
      "metadata": {
        "id": "K5W4x9T-c_Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_xgb = BayesSearchCV(estimator=pipeline, search_spaces=param_space_xgb, n_iter=50, cv=3, n_jobs=-1, random_state=42)"
      ],
      "metadata": {
        "id": "r_hUyg5SdBvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터 준비\n",
        "X_train = train_df.drop(columns=['ID', 'y'])\n",
        "y_train = train_df['y']"
      ],
      "metadata": {
        "id": "cy5MUoGsdDUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train의 결측값 처리\n",
        "X_train = X_train[~y_train.isnull()]\n",
        "y_train = y_train.dropna()"
      ],
      "metadata": {
        "id": "bKQrrz_FdFhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 검색 공간 정의\n",
        "param_space_xgb = {\n",
        "    'model__n_estimators': (100, 1000),\n",
        "    'model__max_depth': (3, 15),\n",
        "    'model__learning_rate': (0.01, 0.3, 'log-uniform'),\n",
        "    'model__subsample': (0.5, 1.0),\n",
        "    'model__colsample_bytree': (0.5, 1.0),\n",
        "    'model__min_child_weight': (1, 10)\n",
        "}"
      ],
      "metadata": {
        "id": "avfFJQ9rdHP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayesian Optimization 설정\n",
        "opt_xgb = BayesSearchCV(estimator=pipeline, search_spaces=param_space_xgb, n_iter=50, cv=3, n_jobs=-1, random_state=42)"
      ],
      "metadata": {
        "id": "9Wp_YrgadJpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터 준비\n",
        "X_train = train_df.drop(columns=['ID', 'y'], errors='ignore')\n",
        "y_train = train_df['y']"
      ],
      "metadata": {
        "id": "XqmzFDRXdLcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train의 결측값 처리\n",
        "X_train = X_train[~y_train.isnull()]\n",
        "y_train = y_train.dropna()"
      ],
      "metadata": {
        "id": "yq2S2tsqdNUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_xgb.fit(X_train, y_train)\n",
        "print(\"Best hyperparameters for XGBoost:\", opt_xgb.best_params_)"
      ],
      "metadata": {
        "id": "5-TIE94GdPfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best hyperparameters for XGBoost: OrderedDict([('model__colsample_bytree', 0.5), ('model__learning_rate', 0.013066302749068358), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 1000), ('model__subsample', 0.8081268064180479)])"
      ],
      "metadata": {
        "id": "JXoJkU-nomee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터 예측\n",
        "X_test = test_df.drop(columns=['ID'])\n",
        "y_test_pred_xgb = opt_xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "ypNjVFgFdRM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 평가 (학습 데이터에서 성능 검증)\n",
        "X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "opt_xgb.fit(X_train_part, y_train_part)\n",
        "y_valid_pred_xgb = opt_xgb.predict(X_valid)\n",
        "mse_xgb = mean_squared_error(y_valid, y_valid_pred_xgb)\n",
        "r2_xgb = r2_score(y_valid, y_valid_pred_xgb)\n",
        "print(f\"Validation Mean Squared Error (XGBoost): {mse_xgb:.4f}\")\n",
        "print(f\"Validation R-squared (XGBoost): {r2_xgb:.4f}\")"
      ],
      "metadata": {
        "id": "sf41C7CdoX4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 33% 임계값 계산\n",
        "threshold_xgb = np.percentile(y_test_pred_xgb, 67)\n",
        "top_33_percent_mask_xgb = y_test_pred_xgb >= threshold_xgb"
      ],
      "metadata": {
        "id": "SmgIG_xsoZ8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 제출 파일 생성\n",
        "submission_df_xgb = pd.read_csv('sample_submission.csv')\n",
        "submission_df_xgb['y'] = y_test_pred_xgb\n",
        "submission_df_xgb.to_csv('xgb_feature_submission.csv', index=False)\n",
        "\n",
        "print(f\"Top 33% threshold (XGBoost): {threshold_xgb:.4f}\")\n",
        "print(f\"Number of samples in top 33% (XGBoost): {sum(top_33_percent_mask_xgb)}\")\n",
        "print(\"Submission file 'xgb_updated_submission.csv' created successfully.\")"
      ],
      "metadata": {
        "id": "VtZhjrq6rHqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 33% threshold (XGBoost): 84.4860\n",
        "Number of samples in top 33% (XGBoost): 1646\n",
        "Submission file 'xgb_updated_submission.csv' created successfully."
      ],
      "metadata": {
        "id": "6EnzjtVmrR3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from lightgbm import LGBMRegressor\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 데이터 로드\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# 데이터 확인\n",
        "print(\"Train DataFrame columns:\", train_df.columns)\n",
        "\n",
        "# Feature Engineering\n",
        "\n",
        "# 수치형과 범주형 특성 선택\n",
        "numerical_features = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# 'ID'와 'y'는 제거\n",
        "numerical_features = [col for col in numerical_features if col not in ['ID', 'y']]\n",
        "categorical_features = [col for col in categorical_features if col != 'ID']\n",
        "\n",
        "print(\"Numerical features:\", numerical_features)\n",
        "print(\"Categorical features:\", categorical_features)\n",
        "\n",
        "# 결측값 대체 전략 설정\n",
        "numerical_transformer = SimpleImputer(strategy='mean')\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# 컬럼 변환기를 통해 수치형과 범주형에 다른 전처리 적용\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'  # 나머지 컬럼은 그대로 유지\n",
        ")\n",
        "\n",
        "# 전처리 및 모델을 포함하는 파이프라인 구성\n",
        "model = LGBMRegressor(random_state=42, objective='regression', early_stopping_rounds=10)\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('scaler', StandardScaler()),  # 스케일링 추가\n",
        "    ('model', model)\n",
        "])\n",
        "\n",
        "# 하이퍼파라미터 검색 공간 정의\n",
        "param_space_lgbm = {\n",
        "    'model__n_estimators': (50, 2000),\n",
        "    'model__max_depth': (1, 20),\n",
        "    'model__learning_rate': (0.005, 0.3, 'log-uniform'),\n",
        "    'model__subsample': (0.4, 1.0),\n",
        "    'model__colsample_bytree': (0.4, 1.0),\n",
        "    'model__min_child_samples': (1, 50),\n",
        "    'model__reg_alpha': (0.0, 1.0),  # L1 regularization term\n",
        "    'model__reg_lambda': (0.0, 1.0)  # L2 regularization term\n",
        "}\n",
        "\n",
        "# Bayesian Optimization 설정\n",
        "opt_lgbm = BayesSearchCV(\n",
        "    estimator=pipeline,\n",
        "    search_spaces=param_space_lgbm,\n",
        "    n_iter=100,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),  # KFold 사용\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 학습 데이터 준비\n",
        "X_train = train_df.drop(columns=['ID', 'y'])\n",
        "y_train = train_df['y']\n",
        "\n",
        "# 결측값 확인 및 처리\n",
        "print(\"Missing values in X_train before:\", X_train.isnull().sum().sum())\n",
        "print(\"Missing values in y_train before:\", y_train.isnull().sum())\n",
        "\n",
        "# X_train의 결측값은 SimpleImputer로 처리되므로 따로 제거하지 않음\n",
        "y_train = y_train.fillna(y_train.median())  # y_train의 결측값은 중앙값으로 대체\n",
        "\n",
        "# 결측값 확인 후\n",
        "print(\"Missing values in X_train after:\", X_train.isnull().sum().sum())\n",
        "print(\"Missing values in y_train after:\", y_train.isnull().sum())\n",
        "\n",
        "# 모델 학습 및 최적의 하이퍼파라미터 찾기\n",
        "opt_lgbm.fit(X_train, y_train)\n",
        "print(\"Best hyperparameters for LightGBM:\", opt_lgbm.best_params_)\n",
        "\n",
        "# 특성 중요도 확인\n",
        "best_model = opt_lgbm.best_estimator_.named_steps['model']\n",
        "feature_importances = best_model.feature_importances_\n",
        "\n",
        "# 중요도에 따라 특성 정렬\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'feature': numerical_features + list(best_model.booster_.feature_name()),  # one-hot encoding 후 실제 특성 이름 사용\n",
        "    'importance': feature_importances\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "\n",
        "print(feature_importances_df)\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "X_test = test_df.drop(columns=['ID'])\n",
        "y_test_pred_lgbm = opt_lgbm.predict(X_test)\n",
        "\n",
        "# 성능 평가 (학습 데이터에서 성능 검증)\n",
        "X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "opt_lgbm.fit(X_train_part, y_train_part)\n",
        "y_valid_pred_lgbm = opt_lgbm.predict(X_valid)\n",
        "mse_lgbm = mean_squared_error(y_valid, y_valid_pred_lgbm)\n",
        "r2_lgbm = r2_score(y_valid, y_valid_pred_lgbm)\n",
        "print(f\"Validation Mean Squared Error (LightGBM): {mse_lgbm:.4f}\")\n",
        "print(f\"Validation R-squared (LightGBM): {r2_lgbm:.4f}\")\n",
        "\n",
        "# 상위 33% 임계값 계산\n",
        "threshold_lgbm = np.percentile(y_test_pred_lgbm, 67)\n",
        "top_33_percent_mask_lgbm = y_test_pred_lgbm >= threshold_lgbm\n",
        "\n",
        "# 제출 파일 생성\n",
        "submission_df_lgbm = pd.read_csv('sample_submission.csv')\n",
        "submission_df_lgbm['y'] = y_test_pred_lgbm\n",
        "submission_df_lgbm.to_csv('lgbm_updated_submission.csv', index=False)\n",
        "\n",
        "print(f\"Top 33% threshold (LightGBM): {threshold_lgbm:.4f}\")\n",
        "print(f\"Number of samples in top 33% (LightGBM): {sum(top_33_percent_mask_lgbm)}\")\n",
        "print(\"Submission file 'lgbm_updated_submission.csv' created successfully.\")\n"
      ],
      "metadata": {
        "id": "v6i2BSp1rJdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "NL_yoT-DunLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from lightgbm import LGBMRegressor\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "sQd5sWSsuhpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# 데이터 확인\n",
        "print(\"Train DataFrame columns:\", train_df.columns)"
      ],
      "metadata": {
        "id": "bQt3uY-kulFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수치형과 범주형 특성 선택\n",
        "numerical_features = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# 'ID'와 'y'는 제거\n",
        "numerical_features = [col for col in numerical_features if col not in ['ID', 'y']]\n",
        "categorical_features = [col for col in categorical_features if col != 'ID']"
      ],
      "metadata": {
        "id": "UuW8fe00uvdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Numerical features:\", numerical_features)\n",
        "print(\"Categorical features:\", categorical_features)\n",
        "\n",
        "# 결측값 대체 전략 설정\n",
        "numerical_transformer = SimpleImputer(strategy='mean')\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])"
      ],
      "metadata": {
        "id": "pbN4o127u36J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬럼 변환기를 통해 수치형과 범주형에 다른 전처리 적용\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'  # 나머지 컬럼은 그대로 유지\n",
        ")\n",
        "\n",
        "# 전처리 및 모델을 포함하는 파이프라인 구성\n",
        "model = LGBMRegressor(random_state=42, objective='regression', early_stopping_rounds=10)\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('scaler', StandardScaler()),  # 스케일링 추가\n",
        "    ('model', model)\n",
        "])"
      ],
      "metadata": {
        "id": "ToZjxuB7u7Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 검색 공간 정의\n",
        "param_space_lgbm = {\n",
        "    'model__n_estimators': (50, 2000),\n",
        "    'model__max_depth': (1, 20),\n",
        "    'model__learning_rate': (0.005, 0.3, 'log-uniform'),\n",
        "    'model__subsample': (0.4, 1.0),\n",
        "    'model__colsample_bytree': (0.4, 1.0),\n",
        "    'model__min_child_samples': (1, 50),\n",
        "    'model__reg_alpha': (0.0, 1.0),  # L1 regularization term\n",
        "    'model__reg_lambda': (0.0, 1.0)  # L2 regularization term\n",
        "}\n",
        "\n",
        "# Bayesian Optimization 설정\n",
        "opt_lgbm = BayesSearchCV(\n",
        "    estimator=pipeline,\n",
        "    search_spaces=param_space_lgbm,\n",
        "    n_iter=100,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),  # KFold 사용\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "pZgOjAZDu-JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터 준비\n",
        "X_train = train_df.drop(columns=['ID', 'y'])\n",
        "y_train = train_df['y']\n",
        "\n",
        "# 결측값 확인 및 처리\n",
        "print(\"Missing values in X_train before:\", X_train.isnull().sum().sum())\n",
        "print(\"Missing values in y_train before:\", y_train.isnull().sum())"
      ],
      "metadata": {
        "id": "m_x1G7mOvA9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train의 결측값은 SimpleImputer로 처리되므로 따로 제거하지 않음\n",
        "y_train = y_train.fillna(y_train.median())  # y_train의 결측값은 중앙값으로 대체\n",
        "\n",
        "# 결측값 확인 후\n",
        "print(\"Missing values in X_train after:\", X_train.isnull().sum().sum())\n",
        "print(\"Missing values in y_train after:\", y_train.isnull().sum())"
      ],
      "metadata": {
        "id": "S4DHGsGivDTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 및 최적의 하이퍼파라미터 찾기\n",
        "opt_lgbm.fit(X_train, y_train)\n",
        "print(\"Best hyperparameters for LightGBM:\", opt_lgbm.best_params_)\n",
        "\n",
        "# 특성 중요도 확인\n",
        "best_model = opt_lgbm.best_estimator_.named_steps['model']\n",
        "feature_importances = best_model.feature_importances_"
      ],
      "metadata": {
        "id": "1f7oleq0vGTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "ubnb__oO8BL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 데이터 로드\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Feature Engineering\n",
        "numerical_features = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "numerical_features = [col for col in numerical_features if col not in ['ID', 'y']]\n",
        "categorical_features = [col for col in categorical_features if col != 'ID']\n",
        "\n",
        "# 데이터 타입 최적화\n",
        "train_df[numerical_features] = train_df[numerical_features].astype(np.float32)\n",
        "test_df[numerical_features] = test_df[numerical_features].astype(np.float32)\n",
        "\n",
        "# 결측값 대체 전략 설정\n",
        "numerical_transformer = SimpleImputer(strategy='mean')\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# 학습 데이터 준비\n",
        "X_train = train_df.drop(columns=['ID', 'y'])\n",
        "y_train = train_df['y']\n",
        "\n",
        "# 결측값 처리\n",
        "y_train = y_train.fillna(y_train.median())\n",
        "\n",
        "# 데이터 전처리\n",
        "X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# 파이프라인 설정\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', CatBoostRegressor(random_state=42, silent=True, task_type='GPU'))\n",
        "])\n",
        "\n",
        "# 하이퍼파라미터 검색 공간 정의\n",
        "param_space = {\n",
        "    'model__iterations': (100, 2000),\n",
        "    'model__depth': (3, 15),\n",
        "    'model__learning_rate': (0.01, 0.3, 'log-uniform'),\n",
        "    'model__l2_leaf_reg': (1, 10),\n",
        "    'model__bagging_temperature': (0.0, 1.0),\n",
        "    'model__border_count': (32, 255)\n",
        "}\n",
        "\n",
        "# Bayesian Optimization 및 교차 검증 설정\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "opt = BayesSearchCV(\n",
        "    estimator=pipeline,\n",
        "    search_spaces=param_space,\n",
        "    n_iter=50,\n",
        "    cv=cv,  # KFold 교차 검증 사용\n",
        "    n_jobs=1,  # 동시 작업자 수 제한\n",
        "    random_state=42,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "\n",
        "# 하이퍼파라미터 최적화 수행\n",
        "opt.fit(X_train, y_train, model__cat_features=categorical_features)\n",
        "print(\"Best hyperparameters:\")\n",
        "print(opt.best_params_)\n",
        "\n",
        "# 최적 하이퍼파라미터로 전체 학습 데이터로 모델 학습\n",
        "best_model = opt.best_estimator_.named_steps['model']\n",
        "train_pool = Pool(X_train_transformed, y_train, cat_features=categorical_features)\n",
        "\n",
        "best_model.fit(\n",
        "    train_pool,\n",
        "    eval_set=train_pool,\n",
        "    early_stopping_rounds=10,\n",
        "    use_best_model=True,\n",
        "    task_type='GPU'  # GPU 사용 설정\n",
        ")\n",
        "\n",
        "# 검증 데이터 예측\n",
        "y_train_pred = best_model.predict(train_pool)\n",
        "mse = mean_squared_error(y_train, y_train_pred)\n",
        "r2 = r2_score(y_train, y_train_pred)\n",
        "print(f\"Training Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"Training R-squared: {r2:.4f}\")\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "X_test = test_df.drop(columns=['ID'])\n",
        "X_test_transformed = preprocessor.transform(X_test)\n",
        "test_pool = Pool(X_test_transformed, cat_features=categorical_features)\n",
        "\n",
        "y_test_pred = best_model.predict(test_pool)\n",
        "\n",
        "# 상위 33% 임계값 계산\n",
        "threshold = np.percentile(y_test_pred, 67)\n",
        "top_33_percent_mask = y_test_pred >= threshold\n",
        "\n",
        "# 제출 파일 생성\n",
        "submission_df = pd.read_csv('sample_submission.csv')\n",
        "submission_df['y'] = y_test_pred\n",
        "submission_df.to_csv('catboost_updated_submission.csv', index=False)\n",
        "\n",
        "print(f\"Top 33% threshold: {threshold:.4f}\")\n",
        "print(f\"Number of samples in top 33%: {sum(top_33_percent_mask)}\")\n",
        "print(\"Submission file 'catboost_updated_submission.csv' created successfully.\")\n"
      ],
      "metadata": {
        "id": "X1pW0fhzvJP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Mean Squared Error: 2.7204\n",
        "Training R-squared: 0.6238\n",
        "Top 33% threshold: 84.4735\n",
        "Number of samples in top 33%: 1646\n",
        "Submission file 'lgbm_updated_submission.csv' created successfully."
      ],
      "metadata": {
        "id": "f2eO9svG7vvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "id": "BZYCmLiEvkSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabgan==1.3.3"
      ],
      "metadata": {
        "id": "lpMmulmxv8iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o7uXhHxCwGfT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}